{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pdb; pdb.set_trace()\n",
    "\n",
    "%matplotlib inline  \n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# connection to the database\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# set username/password here:\n",
    "db = {'username': os.environ['USERNAME_11323671'],\n",
    "      'password': os.environ['PASSWORD_11323671'],\n",
    "      'host': 'quantleap.nl:5432',\n",
    "      'catalog': 'qir'}\n",
    "\n",
    "con = 'postgresql://{username}:{password}@{host}/{catalog}'.format(**db)\n",
    "engine = create_engine(con, echo=True)\n",
    "print('CONNECTION ESTABLISHED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insolvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"select count(distinct case_number) \n",
    "         from company_insolvents\"\"\"\n",
    "\n",
    "no_insolvents = pd.read_sql(sql, con).iloc[0][0]\n",
    "print('the total number of insolvents cases in the database is {}'.format(no_insolvents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"select start_date_insolvency is not null as known, count(*)\n",
    "         from company_insolvents\n",
    "         group by start_date_insolvency is not null\"\"\"\n",
    "\n",
    "df_known_start_date = pd.read_sql(sql, con)\n",
    "print('fraction of known start date')\n",
    "df_known_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_known_start_date.plot.pie(y='count', labels=df_known_start_date['known'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Judges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"select count(supervisory_judge) as no_cases, supervisory_judge\n",
    "         from company_insolvents\n",
    "         group by 2\n",
    "         order by 1 desc\n",
    "         limit 10\"\"\"\n",
    "\n",
    "print(\"top 10 judges by number of cases\")\n",
    "pd.read_sql(sql, con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of non normalized judge names:\n",
    "\n",
    "- \"mr. W.J.  Geurts - de Veld\"\n",
    "- \"mr. W.J. Geurts - de Veld\"\n",
    "- \"mr. W.J. Geurts-deVeld\"\n",
    "- \"mr. W.J. Geurts-de Veld\"\n",
    "- \"mr. W.J.Geurts-de Veld\"\n",
    "- \"mr.W.J. Geurts-de Veld\"\n",
    "- \"mr. W.J. Geurts-de Veld (Rotterdam)\"\n",
    "- \"mr W.J.Geurts-de Veld\"\n",
    "- \"W.J.Geurts-de Veld\"\n",
    "\n",
    "correct: \"mr. W.J. Geurts-de Veld\"\n",
    "normalized: \"wj geurts-de veld\"\n",
    "\n",
    "normalization steps:\n",
    "1. make lowercase\n",
    "2. remove leading mr[.]\n",
    "3. remove spaces around dash\n",
    "4. remove dots\n",
    "5. replace double spaces by single space\n",
    "6. remove parentheses and text within\n",
    "7. strip leading and trailing spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"select distinct supervisory_judge\n",
    "         from company_insolvents\n",
    "         where supervisory_judge notnull\n",
    "         order by 1\"\"\"\n",
    "\n",
    "non_normalized_name = pd.read_sql(sql, con)\n",
    "\n",
    "def normalize_judge_name(name):\n",
    "    return name.replace(r\"\\(.*\\)\",\"\")\n",
    "    \n",
    "\n",
    "non_normalized_name['supervisory_judge'].apply(normalize_judge_name)[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rechters_df = pd.read_html('http://ors.openstate.eu/relations')[0]\n",
    "rechters_df = pd.read_json('http://ors.openstate.eu/relations/json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rechters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rechters_df[rechters_df['set'] == 'Rechtbank Amsterdam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verslagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split voortgangs vs financiele rapportages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"select \n",
    "           count(*), \n",
    "           count(*)::decimal/(select count(*) from reports)*100 as pct, \n",
    "           right(identification, 1) = 'B' as is_financial_report\n",
    "         from reports\n",
    "         group by 3;\"\"\"\n",
    "pd.read_sql(sql, con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split PDF was scanned vs converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"select \n",
    "           count(*), \n",
    "           count(*)::decimal/(select count(*) from reports)*100 as pct, \n",
    "           is_ocr as was_scanned\n",
    "         from reports\n",
    "         group by 3;\"\"\"\n",
    "pd.read_sql(sql, con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: run new classifier over all pdfs on S3 for unknowns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## praktijk van het rapporteren voortgangsverslagen met/zonder financiele bijlage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"select * from progess_financial_report_cooccurence;\"\"\"\n",
    "df = pd.read_sql(sql, con)\n",
    "df = df.transpose()\n",
    "df.columns = ['count']\n",
    "df['pct'] = df['count']/df['count'].sum()*100\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rapportages over tijd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     8,
     14,
     15
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "with\n",
    "financial as (\n",
    "      select to_char(publication_date, 'YYYY-MM') as month,\n",
    "             count(*) as financial_count\n",
    "      from reports\n",
    "      where right(identification, 1) = 'B'\n",
    "      group by 1),\n",
    "progress as (\n",
    "      select to_char(publication_date, 'YYYY-MM') as month,\n",
    "             count(*) as progres_count\n",
    "      from reports\n",
    "      where right(identification, 1) != 'B'\n",
    "      group by 1)\n",
    "select prog.month as maand, progres_count as voortgangsverslag, coalesce(financial_count, 0) as financieelverslag\n",
    "  from financial fin\n",
    "    full outer join progress prog on fin.month = prog.month\n",
    "  order by prog.month;\n",
    "\"\"\"\n",
    "df = pd.read_sql(sql, con, index_col=\"maand\")\n",
    "df.plot.bar(stacked=True, figsize=(20, 5), title='publicaties per maand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## steekproef van niet OCR eindverslagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = '''SELECT identification, publication_date, is_end_report, content, start_date_insolvency\n",
    "         FROM reports rep\n",
    "             JOIN company_insolvents ins ON rep.insolvent_id = ins.id\n",
    "         WHERE rep.is_end_report = TRUE\n",
    "             AND is_ocr is FALSE\n",
    "         ORDER BY publication_date DESC\n",
    "         LIMIT 1000;'''\n",
    "\n",
    "df_reports = pd.read_sql(sql, con, index_col='identification')\n",
    "df_reports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data field wish list from the PDF report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wenselijke datavelden in het voortgangsverslag\n",
    "Het voortgangsverslag hoort gestructureerd te zijn volgens de RECOFA richtlijnenm zie **model-verslag-faillissement-rechtspersoon.pdf**. In eerste instantie zijn we geinteresseerd in de data uit de **eindverslagen**.\n",
    "\n",
    "Algemeen\n",
    "- Personeel gemiddeld aantal: aantal\n",
    "- Bestede uren totaal: aantal\n",
    "- Saldo boedelrekening: bedrag\n",
    "\n",
    "\n",
    "4 Debiteuren\n",
    "\n",
    "4.2 Opbrengst: bedrag\n",
    "\n",
    "\n",
    "7 Rechtmatigheid\n",
    "\n",
    "7.2 Depot jaarrekeningen: wel/niet \n",
    "\n",
    "7.5 Onbehoorlijk bestuur: wel/niet\n",
    "\n",
    "\n",
    "8 Crediteuren\n",
    "\n",
    "8.1 Boedelvorderingen: bedrag (salaris curator / UWV / ..)\n",
    "\n",
    "8.2 Preferente vorderingen van de fiscus: bedrag\n",
    "\n",
    "8.3 Preferente vorderingen van het UWV: bedrag\n",
    "\n",
    "8.4 Andere preferente vorderingen: bedrag\n",
    "\n",
    "8.5 Aantal concurrente crediteuren: bedrag\n",
    "\n",
    "8.6 Bedrag concurrente crediteuren: bedrag\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bevindingen / Issues\n",
    "- Bij insolventen van verslagen 13_ams_15_478_F_V_06 en 10_rot_12_90_F_V_16 zijn geen enkele financiele verslagen ook curator salaris wordt niet genoemd. Vraag: wie levert geen financieel verslag en waarom?\n",
    "- Bij eindverslag 10_rot_14_1054_F_V_10 staat curator salaris alleen in de financiele bijlage. Er lijkt ook sprake van een schikking - regeling bestuurder: 22.000 - wegens rechtmatigheidsissue. \n",
    "- bij 11_rot_12_41_F_V_15 staan bedragen doorgestreept, textconversie pakt dat niet\n",
    "- De eindverslagen zijn niet echt eindverslagen: 'Naar verwachting zal het faillissement in de komende\n",
    "verslagperiode eindigen.' (11_rot_12_41_F_V_15)\n",
    "- uurtarief bij 11_rot_12_41_F_V_15 komt op 280,-\n",
    "- 10_rot_14_1054_F_V_10, 01_obr_13_293_F_V_09 omzetting pdf>txt verliest letters/gegevens/structuur met PDFMiner. Welke converter pakt dit goed aan ?\n",
    "- strikethrough in PDF komt niet terug in de tekstconversie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Extracting structured text from PDF reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kandidaat sectie headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1: extract sections from progress reports\n",
    "# Sub step: extract candidate sections from model report\n",
    "model_content = open('model-verslag-faillissement-rechtspersoon.txt', 'r').read()\n",
    "\n",
    "def match_headings(content, level=2):\n",
    "    \"\"\" returns level 2 (e.g. 1.1) heading matches as tuple (heading number, heading title)\"\"\"\n",
    "    flags = re.MULTILINE\n",
    "    if level == 2:\n",
    "        pattern = r\"^\\s*(\\d{1,2}\\.\\d{1,2})\\s*(.*)$\"\n",
    "    elif level == 1:\n",
    "        pattern = r\"^\\s*(\\d{1,2}\\.\\d{0,2})\\s*(.*)$\"\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    match = re.findall(pattern, content, flags)\n",
    "    return match\n",
    "\n",
    "model_headings = match_headings(model_content, level=1)\n",
    "model_heading_numbers = list(zip(*model_headings))[0]\n",
    "model_headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report_content = df_reports['content']['01_obr_13_1204_F_V_04']\n",
    "print(report_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report_headings = match_headings(report_content, level=1)\n",
    "report_heading_numbers = list(zip(*report_headings))[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is strictly increasing: True\n",
      "all headings report in model: True\n"
     ]
    }
   ],
   "source": [
    "# BREADTH FIRST SEARCH: eerst van zoveel mogelijk rapporten een zo weid mogelijk net uitgooien, dan inzoomen\n",
    "# 0. eigenlijk eerst full text search op gehele content\n",
    "# 1. search op sections\n",
    "# 2. search op parameter values\n",
    "\n",
    "# SECTIONS\n",
    "# check hoeveel er exact matchen(ignore case)\n",
    "# check hoeveel er op heading nummers matchen\n",
    "# for stop anchor point we need to level 1 headings too\n",
    "\n",
    "# ZOU MATCH OP HEADING NUMMER AL GENOEG KUNNEN ZIJN ? :\n",
    "# check of heading nummers oplopen\n",
    "# check of heading nummers in kandidatenlijst voorkomen\n",
    "\n",
    "# level 1 pattern with .? yields many false positives (in first examined case)\n",
    "\n",
    "def is_strictly_increasing_heading_numbers(heading_numbers):\n",
    "    \"\"\" checks if all level 2 headings 1.1, 1.2, 3.1 etc in list are strictly increasing. \"\"\"\n",
    "    if heading_numbers is not None:\n",
    "        return all([float(a) < float(b) for (a, b) in zip(heading_numbers, heading_numbers[1:])])\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def only_model_headings(report_heading_numbers):\n",
    "    if report_heading_numbers is not None:\n",
    "        report_headings_not_in_model = set(report_heading_numbers).difference(set(model_heading_numbers))\n",
    "        return len(report_headings_not_in_model) == 0\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_heading_numbers(content):\n",
    "    headings = match_headings(content)\n",
    "    if headings:\n",
    "        heading_numbers, _ = list(zip(*headings))\n",
    "        return heading_numbers\n",
    "    else:\n",
    "        return None\n",
    "  \n",
    "\n",
    "\n",
    "print('is strictly increasing: {}'.format(is_strictly_increasing_heading_numbers(report_heading_numbers)))\n",
    "print('all headings report in model: {}'.format(all_report_headings_in_model(report_heading_numbers, model_heading_numbers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store matched headers as json strings\n",
    "df_reports['headings'] = df_reports['content'].apply(lambda x: json.dumps(match_headings(x)))\n",
    "df_reports['headings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_reports['heading_numbers'] = df_reports['content'].apply(lambda x: json.dumps(get_heading_numbers(x)))\n",
    "df_reports['heading_numbers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_reports['strictly_increasing'] = df_reports['heading_numbers'].apply(\n",
    "    lambda x: is_strictly_increasing_heading_numbers(json.loads(x)))\n",
    "df_reports['strictly_increasing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.400000000000002"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# report percentage strictly increasing\n",
    "df_reports['strictly_increasing'][df_reports['strictly_increasing'] == True].count() / df_reports['strictly_increasing'].count() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reports['only_model_headings'] = df_reports['heading_numbers'].apply(\n",
    "    lambda x: is_strictly_increasing_heading_numbers(json.loads(x)))\n",
    "df_reports['strictly_increasing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reports['only_model_headings'] = df_reports['heading_numbers'].apply(\n",
    "    lambda x: only_model_headings(json.loads(x)))\n",
    "df_reports['only_model_headings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.700000000000003"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# report percentage only model headings\n",
    "df_reports['only_model_headings'][df_reports['only_model_headings'] == True].count() / df_reports['only_model_headings'].count() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_rot_14_762_F_V_09\n",
      "1.1 1.2 True\n",
      "1.2 1.3 True\n",
      "1.3 1.5 True\n",
      "1.5 1.7 True\n",
      "1.7 2.1 True\n",
      "2.1 2.3 True\n",
      "2.3 5.1 True\n",
      "5.1 5.2 True\n",
      "5.2 5.4 True\n",
      "5.4 5.6 True\n",
      "5.6 5.8 True\n",
      "5.8 7.1 True\n",
      "7.1 7.2 True\n",
      "7.2 7.4 True\n",
      "7.4 8.1 True\n",
      "8.1 8.3 True\n",
      "8.3 8.5 True\n",
      "8.5 7.6 False\n",
      "7.6 10.1 True\n",
      "10.1 10.3 True\n"
     ]
    }
   ],
   "source": [
    "# inspect not strictly increasing\n",
    "df_not_increasing = df_reports[df_reports.only_model_headings & (~df_reports.strictly_increasing)]\n",
    "index = 20\n",
    "print(df_not_increasing.index[index])\n",
    "heading_numbers = list(zip(*json.loads(df_not_increasing.headings[index])))[0]\n",
    "is_strictly_increasing_heading_numbers(heading_numbers)\n",
    "for a, b in zip(heading_numbers, heading_numbers[1:]):\n",
    "    print(float(a), float(b), float(a)<float(b))\n",
    "    \n",
    "# finding: in many reports 3.10 became 3.1 even though the PDF shows 3.10, PDFMiner issue ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is-ds-thesis",
   "language": "python",
   "name": "is-ds-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
