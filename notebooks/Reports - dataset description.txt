
#import pdb; pdb.set_trace()

%matplotlib inline  
import pandas as pd
import os
import re
import json
import psycopg2
from sqlalchemy.engine.url import URL

# connection to the database
# connection string for use in pandas:
con = str(URL(drivername='postgresql', 
              username=os.environ['DB_QIR_USERNAME'], 
              password=os.environ['DB_QIR_PASSWORD'], 
              host='www.quantleap.nl', 
              database='qir'))

# cursor for use with psycopg2
conn = psycopg2.connect(con)
cur = conn.cursor()  
print('CONNECTION ESTABLISHED')

sql = """
with
financial as (
      select to_char(publication_date, 'YYYY-MM') as month,
             count(*) as financial_report_count
      from reports
      where right(identification, 1) = 'B'
      group by 1),
progress as (
      select to_char(publication_date, 'YYYY-MM') as month,
             count(*) as progres_report_count
      from reports
      where right(identification, 1) != 'B'
      group by 1)
select prog.month, progres_report_count, coalesce(financial_report_count, 0) as financial_report_count
  from financial fin
    full outer join progress prog on fin.month = prog.month
  order by prog.month;
"""
df = pd.read_sql(sql, con, index_col="month")
df.plot.bar(stacked=True, figsize=(15, 4), title='report publications per month')

sql = '''select identification, is_ocr, is_on_disk, publication_date, is_extractable
         from reports 
         where extract(year from publication_date) >= 2014
             and extract(year from publication_date) <= 2017
             and is_attachment=False;'''
df = pd.read_sql(sql, con, index_col='publication_date')

print('The dataset to be used contains {} progress reports in period 2014 - 2017'.format(len(df)))
df.head()

total = df['identification'].resample('M').count()
total

df_on_disk = df[df.is_on_disk == True]
on_disk = df_on_disk.is_on_disk.resample('M').count()
on_disk

(on_disk / total).plot.barh(title='Downloaded progress reports as pct', xlim=[0,1], figsize=(15, 15))

df_on_disk_and_not_scanned = df_on_disk[df_on_disk.is_ocr == False]
on_disk_and_not_scanned = df_on_disk_and_not_scanned['is_ocr'].resample('M').count()
on_disk_and_not_scanned

(on_disk_and_not_scanned / on_disk).plot.barh(title='Textual progress reports on disk as pct', xlim=[0,1], figsize=(15, 15))

df_is_extractable = df_on_disk_and_not_scanned[df_on_disk_and_not_scanned.is_extractable == True]
is_extractable = df_is_extractable.is_extractable.resample('M').count()
is_extractable

(is_extractable / on_disk_and_not_scanned).plot.barh(title='Extractable textual progress reports on disk as pct', xlim=[0,1], figsize=(15, 15))

(is_extractable / total).plot.barh(title='Extractable textual progress reports on disk as pct of total', xlim=[0,1], figsize=(15, 15))

sql = '''SELECT identification, content
         FROM reports 
         WHERE extract(year from publication_date) >= 2014
             AND extract(year from publication_date) <= 2017
             AND is_attachment = FALSE
             AND is_ocr = FALSE 
             AND is_extractable = TRUE
             AND content IS NOT NULL
         ORDER BY publication_date ASC
         LIMIT 100;'''
df = pd.read_sql(sql, con, index_col='identification')
df.head(n=10)

# Step 1: extract section anchor points from progress reports
# Sub step: extract candidate sections from model report
model_content = open('model-verslag-faillissement-rechtspersoon.txt', 'r').read()

def match_headings(content, level=2):
    """ returns level 2 (e.g. 1.1) heading matches as tuple (heading number, heading title)"""
    flags = re.MULTILINE
    if level == 2:
        pattern = r"^\s*(\d{1,2}\.\d{1,2})\s*(.*)$"
    elif level == 12:  # level 1 and level 2
        pattern = r"^\s*(\d{1,2}\.\d{0,2})\s*(.*)$"
    else:
        raise NotImplementedError
    match = re.findall(pattern, content, flags)
    return match if match is not None else []

model_headings = [('0.0', 'Introduction')] + match_headings(model_content, level=2)
model_heading_numbers = list(zip(*model_headings))[0]
print(len(model_headings))
model_headings

# Example (first) report
report_content = df['content'][0]
report_headings = match_headings(report_content, level=12)  # match level 2 headings
report_heading_numbers = list(zip(*report_headings))[0]
print(report_content)
print(report_headings)

# SECTIONS
# check hoeveel er exact matchen(ignore case)
# check hoeveel er op heading nummers matchen
# for stop anchor point we need to level 1 headings too

# ZOU MATCH OP HEADING NUMMER AL GENOEG KUNNEN ZIJN ? :
# check of heading nummers oplopen
# check of heading nummers in kandidatenlijst voorkomen

# level 1 pattern with .? yields many false positives (in first examined case)

def is_strictly_increasing_heading_numbers(heading_numbers):
    """ checks if all level 2 headings 1.1, 1.2, 3.1 etc in list are strictly increasing. """
    return all([float(a) < float(b) for (a, b) in zip(heading_numbers, heading_numbers[1:])])

def has_only_model_heading_numbers(report_heading_numers):
    """ checks if report heading numbers are all present in the model heading numbers. """
    return set(report_heading_numers) <= set(model_heading_numbers)

def get_heading_numbers(content):
    headings = match_headings(content)
    if headings:
        heading_numbers, _ = list(zip(*headings))
        return heading_numbers
    else:
        return []
  
def model_heading_coverage(report_heading_numbers):
    """ return the number of headings found as percentage of the model report. """
    pass

%run progress_report_extractor
report_content = df['content'][0]
print(extract_section(report_content, '7.6'))  # paulianeus handelen

# make sections columns in the dataframe - capture section content and length
%run progress_report_extractor
extractor = ProgressReportSectionExtractor()
sections = extractor.sections.keys()  # all available sections
for section in sections:
    section_column = extractor.section_id(section)
    df[section_column] = df['content'].apply(lambda x: extract_section(x, section))
    df[section_column+'_length'] = df[section_column].str.len()
df.head(5)

# empty section percentages - no match 
df[[col for col in list(df) if 'length' not in col]].isnull().sum()/df.shape[0]*100

# Result: better adherence to the model report over time

earliers 200 reports in 2014, pct of empty sections:
introduction                          21.0
directie_en_organisatie               25.5
oorzaak_faillissement                 34.5
aantal_ten_tijde_van_faillissement    38.5
boekhoudplicht                        27.0
onbehoorlijk_bestuur                  26.0
paulianeus_handelen                   93.0
boedelvorderingen                     10.5
pref_vord_van_de_fiscus                9.0
pred_vord_van_het_uwv                 13.0
andere_pred_crediteuren               14.5
aantal_concurrente_crediteuren        14.5
bedrag_concurrente_crediteuren        16.0

most recent 200 reports in 2017 pct of empty sections:
content                               0.0
introduction                          2.0
directie_en_organisatie               2.5
oorzaak_faillissement                 8.5
aantal_ten_tijde_van_faillissement    3.0
onbehoorlijk_bestuur                  7.5
paulianeus handelen                   7.0
boekhoudplicht                        8.0
paulianeus_handelen                   7.0
boedelvorderingen                     5.0
pref_vord_van_de_fiscus               5.0
pred_vord_van_het_uwv                 6.0
andere_pred_crediteuren               6.5
aantal_concurrente_crediteuren        6.5
bedrag_concurrente_crediteuren        6.0



# inspect Nones when heading/keyword is present
df[df['paulianeus_handelen'].isnull() & df['content'].str.contains('paulianeus')]['content'][0:5]

# analyze section length distribution - analyse [false / too long] matches
cols = [col for col in list(df) if 'length' in col and not df[col].isnull().all()]
ax = df.boxplot(column=cols, figsize=(20, 5))
ax.set_ylim(0, 5000)

# test regex on report content
content = df['content']['03_lim_13_41_F_V_02']
pattern = '(?:inventarisatie.*\n1)(.*?)(?:\n2)'
match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
if match:
    print(match.group())
else:
    print('no match')


