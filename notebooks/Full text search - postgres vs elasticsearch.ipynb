{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postgres\n",
    "\n",
    "- always synced with rest of the data already stored in Postgres\n",
    "- The accuracy of PostgreSQL searches is not the best.\n",
    "- speed deteriorates around 1 to 2 million rows\n",
    "\n",
    "## Vector Space Model\n",
    "based on Vector Space Model (VSM) of information retrieval.<br/>\n",
    "_tsvector_ datatype stores document as a vector\n",
    "\n",
    "#### Tokenization\n",
    "Tokenization: splitting text into tokens. Built in tokenizers/parsers:<br/>\n",
    "https://www.postgresql.org/docs/current/static/textsearch-parsers.html <br/>\n",
    "test and debug using *ts_parse* and *ts_debug* function\n",
    "\n",
    "#### Lexenes\n",
    "Dictionaries applied to tokens using stopwords, stemmers and synonyms create lexemes.<br/>\n",
    "Postgres uses Porter Snowball stemming by default.<br/>\n",
    "test using *ts_lexize*\n",
    "\n",
    "#### Configuration\n",
    "verify parser and dictionary config:<br/>\n",
    "SHOW default_text_search_config;<br/>\n",
    "config can be set at cluster, database, session and query level.\n",
    "\n",
    "#### Vectorize\n",
    "Vectorize document: to_tsvector('dutch', document), stores word position<br/>\n",
    "posibility to coalesce text fields (e.g. title and body) and influence indidual vector weights and configs.\n",
    "\n",
    "#### Indexing\n",
    "Two index types for tsvector column:\n",
    "1. GIN - generalized inverted index - default, specifically for large documents, large indexation time\n",
    "2. GiST - generalized search tree - tree, rebalancing, small indexation time\n",
    "\n",
    "## Operational\n",
    "1. Add tsvector column to store vectorized document\n",
    "2. update values using to_tsvector(document)\n",
    "3. set tsvector_update_trigger or own-rolled to create document vectors for inserted/updated documents\n",
    "\n",
    "# Queries\n",
    "Are in the tsquery data type.<br/>\n",
    "Single tokens separated by the Boolean operators & (AND), | (OR) and ! (NOT).\n",
    "\n",
    "# Ranking\n",
    "Build in ranking functions take into account:\n",
    "- lexical info: how often occur the words\n",
    "- proximity info: how close togerher are the words\n",
    "- structural info: in which part of the doc do the words appear\n",
    "\n",
    "functions:\n",
    "1. ts_rank: term frequency\n",
    "2. ts_rank_cd: cover density, includes proximity\n",
    "\n",
    "weights:\n",
    "normalization option to correct for document length:\n",
    "\n",
    "0 (the default) ignores the document length\n",
    "\n",
    "1 divides the rank by 1 + the logarithm of the document length\n",
    "\n",
    "2 divides the rank by the document length\n",
    "\n",
    "4 divides the rank by the mean harmonic distance between extents (this is implemented only by ts_rank_cd)\n",
    "\n",
    "8 divides the rank by the number of unique words in document\n",
    "\n",
    "16 divides the rank by 1 + the logarithm of the number of unique words in document\n",
    "\n",
    "32 divides the rank by itself + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elasticsearch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is-ds-thesis",
   "language": "python",
   "name": "is-ds-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
