
# coding: utf-8

# #### Setup

# In[130]:


#import pdb; pdb.set_trace()

get_ipython().magic('matplotlib inline')
import pandas as pd
import os
import re
import json
import psycopg2
from sqlalchemy.engine.url import URL

# connection to the database
# connection string for use in pandas:
con = str(URL(drivername='postgresql', 
              username=os.environ['DB_QIR_USERNAME'], 
              password=os.environ['DB_QIR_PASSWORD'], 
              host='www.quantleap.nl', 
              database='qir'))

# cursor for use with psycopg2
conn = psycopg2.connect(con)
cur = conn.cursor()  
print('CONNECTION ESTABLISHED')


# # Report data set description
# 
# The data set used in this study contains all the PDF reports published in 2017.
# 
# There are two types of reports: 
# 1. progress reports, containing text based on a RECOFA template
# 2. financial reports, containing tables - [todo: determine conformance with RECOFA template]
# 
# Most often [todo: measure] the financial reports are attached to a progress report: both are published on the same date and the identification number is equal, only the financial report has '\_B' as a postfix.
# 
# Initially we will be focussing on the progress reports as these have more structure and contain more of the data we want to retreive to answer the research questions.

# ## report publication over time
# An overview is given on the published reports over time in the CIR register. From 2014 onwards it shows a steady flow of reports and the trend of a larger portion of financial reports attached to the progress reports, although it has not reached 100% (same amount of both progress and financial reports).
# 
# For the purpose of this study the progress reports published in 2017 will be used.

# In[131]:


sql = """
with
financial as (
      select to_char(publication_date, 'YYYY-MM') as month,
             count(*) as financial_report_count
      from reports
      where right(identification, 1) = 'B'
      group by 1),
progress as (
      select to_char(publication_date, 'YYYY-MM') as month,
             count(*) as progres_report_count
      from reports
      where right(identification, 1) != 'B'
      group by 1)
select prog.month, progres_report_count, coalesce(financial_report_count, 0) as financial_report_count
  from financial fin
    full outer join progress prog on fin.month = prog.month
  order by prog.month;
"""
df = pd.read_sql(sql, con, index_col="month")
df.plot.bar(stacked=True, figsize=(15, 5), title='report publications per month')


# # Completeness checks
# A subselection of the published reports will be used for analysis:
# - reports from 2017
# - downloaded PDF reports (some cannot be downloaded anymore)
# - converted instead of scanned PDFs 
# - reports with extracted text (some PDF reports are encrypted or damaged (absent End of Image / End of File) and text cannot be extracted)
# 
# ## PDF reports downloaded

# In[80]:


sql = '''select identification, is_ocr, is_on_disk, publication_date, is_extractable
         from reports 
         where extract(year from publication_date) >= 2014
             and extract(year from publication_date) <= 2017
             and is_attachment=False;'''
df = pd.read_sql(sql, con, index_col='publication_date')

print('The dataset to be used contains {} progress reports in period 2014 - 2017'.format(len(df)))
df.head()


# In[81]:


total = df['identification'].resample('M').count()
total


# In[82]:


df_on_disk = df[df.is_on_disk == True]
on_disk = df_on_disk.is_on_disk.resample('M').count()
on_disk


# In[97]:


(on_disk / total).plot.barh(title='Downloaded progress reports as pct', xlim=[0,1], figsize=(15, 15))


# Results: not all reports are downloaded/retrieved for the 2017 dataset. Effort will be put into making this set complete. As can be seen specific periods are omitted.

# ## PDF Conversion of progress reports on disk
# 
# PDFs can be generated by:
# 1. scanning printed pages - resulting in an image only document, 
# 2. converting a document to PDF - resulting in a text only document
# 3. scanning printed pages with OCR (Optical Character Recognition) - resulting in a text and image document
# 
# The latter one can have discrepancies between the visible text and extracted text.

# In[88]:


df_on_disk_and_not_scanned = df_on_disk[df_on_disk.is_ocr == False]
on_disk_and_not_scanned = df_on_disk_and_not_scanned['is_ocr'].resample('M').count()
on_disk_and_not_scanned


# In[98]:


(on_disk_and_not_scanned / on_disk).plot.barh(title='Textual progress reports on disk as pct', xlim=[0,1], figsize=(15, 15))


# ## Textual progress reports on disk with extracted text

# In[90]:


df_is_extractable = df_on_disk_and_not_scanned[df_on_disk_and_not_scanned.is_extractable == True]
is_extractable = df_is_extractable.is_extractable.resample('M').count()
is_extractable


# In[99]:


(is_extractable / on_disk_and_not_scanned).plot.barh(title='Extractable textual progress reports on disk as pct', xlim=[0,1], figsize=(15, 15))


# ### Completeness total funnel

# In[100]:


(is_extractable / total).plot.barh(title='Extractable textual progress reports on disk as pct of total', xlim=[0,1], figsize=(15, 15))


# ## Search in progress reports.
# 
# There are three search objectives, each more scoped: 
# 1. to enable full text search over the whole report
# 2. to enable faceted search by heading section
# 3. to extract specific data points as value. 
# 
# ### Full Text Search
# The extracted contents is made searchable using the postgres full text search functionality. (https://www.postgresql.org/docs/9.6/static/textsearch.html)
# 
# ### Faceted search
# The progress reports should be structured in sections according to RECOFA guidelines, see **model-verslag-faillissement-rechtspersoon.pdf**. We like to be able to specificly perform full text search in one of the sections.
# 
# ### data points wish list
# We like to extract specific data point values from the reports. A wish list is given below:
# 
# Algemeen
# - Personeel gemiddeld aantal: **aantal**
# - Bestede uren totaal: **aantal**
# - Saldo boedelrekening: **bedrag**
# 
# 
# 4 Debiteuren
# 
# 4.2 Opbrengst: **bedrag**
# 
# 
# 7 Rechtmatigheid
# 
# 7.2 Depot jaarrekeningen: **wel/niet**
# 
# 7.5 Onbehoorlijk bestuur: **wel/niet**
# 
# 
# 8 Crediteuren
# 
# 8.1 Boedelvorderingen: bedrag (salaris curator / UWV / ..)
# 
# 8.2 Preferente vorderingen van de fiscus: **bedrag**
# 
# 8.3 Preferente vorderingen van het UWV: **bedrag**
# 
# 8.4 Andere preferente vorderingen: **bedrag**
# 
# 8.5 Aantal concurrente crediteuren: **bedrag**
# 
# 8.6 Bedrag concurrente crediteuren: **bedrag**

# #### Enige terloopse bevindingen en issues
# - Bij insolventen van verslagen 13_ams_15_478_F_V_06 en 10_rot_12_90_F_V_16 zijn geen enkele financiele verslagen ook curator salaris wordt niet genoemd. Vraag: wie levert geen financieel verslag en waarom?
# - Bij eindverslag 10_rot_14_1054_F_V_10 staat curator salaris alleen in de financiele bijlage. Er lijkt ook sprake van een schikking - regeling bestuurder: 22.000 - wegens rechtmatigheidsissue. 
# - bij 11_rot_12_41_F_V_15 staan bedragen doorgestreept, textconversie pakt dat niet
# - De eindverslagen zijn niet echt eindverslagen: 'Naar verwachting zal het faillissement in de komende
# verslagperiode eindigen.' (11_rot_12_41_F_V_15)
# - uurtarief bij 11_rot_12_41_F_V_15 komt op 280,-
# - 10_rot_14_1054_F_V_10, 01_obr_13_293_F_V_09 omzetting pdf>txt verliest letters/gegevens/structuur met PDFMiner. Welke converter pakt dit goed aan ?
# - Strikethrough in PDF komt niet terug in de tekstconversie en dit betekent vaak het tegenovergestelde.
# - PDFMiner wisselt soms woordvolgorde en mangled soms letters ook al staat dit duidelijk in het PDF. Dit komt door het formaat: text plus image overlay.
# - PyPDF2 hangt op grote images (voorbeelden '16_mne_13_935_F_V_13', '16_mne_13_1055_F_V_13', '16_mne_12_331_F_V_15', '16_mne_12_326_F_V_15', '16_mne_12_327_F_V_15,' '16_mne_12_384_F_V_15') - een pull request #329 fixt dit.

# ### Faceted search - section extraction
# The RECOFA model progress report contains the following sections to be extracted:
# 
# Step 1: extract section anchor points from progress reports, the level 2 headings
# To extract the introduction we can extract between the beginning and level 1 heading 1.
# 
# Step 2: extract candidate sections from model report

# In[138]:


sql = '''SELECT identification, content
         FROM reports 
         WHERE extract(year from publication_date) >= 2014
             AND extract(year from publication_date) <= 2017
             AND is_attachment = FALSE
             AND is_ocr = FALSE 
             AND is_extractable = TRUE
             AND content IS NOT NULL
         LIMIT 10;'''
df = pd.read_sql(sql, con, index_col='identification')
df.head(n=10)


# In[174]:


# Step 1: extract section anchor points from progress reports
# Sub step: extract candidate sections from model report
model_content = open('model-verslag-faillissement-rechtspersoon.txt', 'r').read()

def match_headings(content, level=2):
    """ returns level 2 (e.g. 1.1) heading matches as tuple (heading number, heading title)"""
    flags = re.MULTILINE
    if level == 2:
        pattern = r"^\s*(\d{1,2}\.\d{1,2})\s*(.*)$"
    elif level == 12:  # level 1 and level 2
        pattern = r"^\s*(\d{1,2}\.\d{0,2})\s*(.*)$"
    else:
        raise NotImplementedError
    match = re.findall(pattern, content, flags)
    return match if match is not None else []

model_headings = [('0.0', 'Introduction')] + match_headings(model_content, level=2)
model_heading_numbers = list(zip(*model_headings))[0]
print(len(model_headings))
model_headings


# In[143]:


# Example report
report_content = df['content']['02_zwb_12_787_F_V_11']
report_headings = match_headings(report_content, level=12)  # match level 2 headings
report_heading_numbers = list(zip(*report_headings))[0]
print(report_content)
print(report_headings)


# In[144]:


# SECTIONS
# check hoeveel er exact matchen(ignore case)
# check hoeveel er op heading nummers matchen
# for stop anchor point we need to level 1 headings too

# ZOU MATCH OP HEADING NUMMER AL GENOEG KUNNEN ZIJN ? :
# check of heading nummers oplopen
# check of heading nummers in kandidatenlijst voorkomen

# level 1 pattern with .? yields many false positives (in first examined case)

def is_strictly_increasing_heading_numbers(heading_numbers):
    """ checks if all level 2 headings 1.1, 1.2, 3.1 etc in list are strictly increasing. """
    return all([float(a) < float(b) for (a, b) in zip(heading_numbers, heading_numbers[1:])])

def has_only_model_heading_numbers(report_heading_numers):
    """ checks if report heading numbers are all present in the model heading numbers. """
    return set(report_heading_numers) <= set(model_heading_numbers)

def get_heading_numbers(content):
    headings = match_headings(content)
    if headings:
        heading_numbers, _ = list(zip(*headings))
        return heading_numbers
    else:
        return []
  
def model_heading_coverage(report_heading_numbers):
    """ return the number of headings found as percentage of the model report. """
    pass


# In[170]:


# try section 1.1 Inventarisatie
# Between - 1.1 Inventarisatie
#     and - 1.2 Winst en verlies

def extract_section(section, content):
    if section = '0.0'
        pattern = '(.*?)(?=\n1.1)'
    elif section = '1.1'
        pattern = '(?<=\n1.1)(.*?)(?=\n1.2)'
        
    m = re.search(pattern, report_content, re.DOTALL)  # dot all includes \n in match for .
    return m.group(0) if m else None  # return full matched string

print(search_pattern('(?<=\n1.1)(.*?)(?=\n1.2)'))


# In[172]:


# try introduction
print(search_pattern('(.*?)(?=\n1.1)'))  # just heading 1 will often not work - use heading 2 levels


# In[ ]:




